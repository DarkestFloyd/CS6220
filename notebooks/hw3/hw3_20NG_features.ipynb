{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20NG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_train = fetch_20newsgroups(\n",
    "    data_home='../data/20newsgroups/', \n",
    "    subset='train')\n",
    "news_test = fetch_20newsgroups(\n",
    "    data_home='../data/20newsgroups/', \n",
    "    subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "counts_train = vectorizer.fit_transform(news_train.data)\n",
    "counts_test = vectorizer.transform(news_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_map = {v: k for k, v in vectorizer.vocabulary_.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 234 ms, sys: 25.7 ms, total: 260 ms\n",
      "Wall time: 260 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_20_chi2, _20_pval = chi2(counts_train, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200 = np.argsort(_20_chi2)[::-1][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['clipper',\n",
       " 'encryption',\n",
       " 'sale',\n",
       " 'dod',\n",
       " 'bike',\n",
       " 'hockey',\n",
       " 'windows',\n",
       " 'israeli',\n",
       " 'israel',\n",
       " 'god']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reverse_map[d] for d in top_200[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_counts_train = counts_train[:, top_200]\n",
    "chi_counts_test = counts_test[:, top_200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "_20_lr = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 809 ms, sys: 36 Âµs, total: 809 ms\n",
      "Wall time: 812 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_20_lr.fit(chi_counts_train, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.707353721053562\n",
      "Test acc: 0.6344928305894849\n"
     ]
    }
   ],
   "source": [
    "yhat = _20_lr.predict(chi_counts_train)\n",
    "print('Train acc:', sum(yhat == news_train.target)/len(news_train.target))\n",
    "_yhat = _20_lr.predict(chi_counts_test)\n",
    "print('Test acc:', sum(_yhyhat = _20_lr.predict(chi_counts_train)\n",
    "print('Train acc:', sum(yhat == news_train.target)/len(news_train.target))\n",
    "_yhat = _20_lr.predict(chi_counts_test)\n",
    "print('Test acc:', sum(_yhat == news_test.target)/len(news_test.target))at == news_test.target)/len(news_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 193 ms, total: 5min 11s\n",
      "Wall time: 5min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_20_mi = mutual_info_classif(counts_train, news_train.target, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200_mi = np.argsort(_20_mi)[::-1][:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['windows',\n",
       " 'god',\n",
       " 'clipper',\n",
       " 'sale',\n",
       " 'dod',\n",
       " 'government',\n",
       " 'team',\n",
       " 'encryption',\n",
       " 'people',\n",
       " 'car']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[reverse_map[d] for d in top_200_mi[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mi_counts_train = counts_train[:, top_200_mi]\n",
    "mi_counts_test = counts_test[:, top_200_mi]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "_20_lr = LogisticRegression(penalty='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.11 s, sys: 2.95 ms, total: 2.11 s\n",
      "Wall time: 2.14 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_20_lr.fit(mi_counts_train, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.7352837192858406\n",
      "Test acc: 0.6313064259160913\n"
     ]
    }
   ],
   "source": [
    "yhat = _20_lr.predict(mi_counts_train)\n",
    "print('Train acc:', sum(yhat == news_train.target)/len(news_train.target))\n",
    "_yhat = _20_lr.predict(mi_counts_test)\n",
    "print('Test acc:', sum(_yhat == news_test.target)/len(news_test.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## strong l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_20_lr = LogisticRegression(penalty='l1', C=0.1, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyclops/workspace/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 38.4 ms, total: 11 s\n",
      "Wall time: 11.1 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "_20_lr.fit(counts_train, news_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.8238465617818632\n",
      "Test acc: 0.7276951672862454\n"
     ]
    }
   ],
   "source": [
    "yhat = _20_lr.predict(counts_train)\n",
    "print('Train acc:', sum(yhat == news_train.target)/len(news_train.target))\n",
    "_yhat = _20_lr.predict(counts_test)\n",
    "print('Test acc:', sum(_yhat == news_test.target)/len(news_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200 = np.argsort(_20_lr.coef_, axis=1)[:,::-1][:,:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done for alt.atheism\n",
      "done for comp.graphics\n",
      "done for comp.os.ms-windows.misc\n",
      "done for comp.sys.ibm.pc.hardware\n",
      "done for comp.sys.mac.hardware\n",
      "done for comp.windows.x\n",
      "done for misc.forsale\n",
      "done for rec.autos\n",
      "done for rec.motorcycles\n",
      "done for rec.sport.baseball\n",
      "done for rec.sport.hockey\n",
      "done for sci.crypt\n",
      "done for sci.electronics\n",
      "done for sci.med\n",
      "done for sci.space\n",
      "done for soc.religion.christian\n",
      "done for talk.politics.guns\n",
      "done for talk.politics.mideast\n",
      "done for talk.politics.misc\n",
      "done for talk.religion.misc\n",
      "CPU times: user 1min 34s, sys: 2.59 s, total: 1min 36s\n",
      "Wall time: 1min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_counts = lil_matrix(counts_train.shape, dtype='int16')\n",
    "for i in range(20):\n",
    "    tg = np.where(news_train.target == i)[0]  \n",
    "    \n",
    "    rows = np.arange(0, len(tg), 1/200)\n",
    "    cols = np.tile(top_200[i], len(tg))\n",
    "    data = [1] * (len(rows))\n",
    "    new_counts[tg] = csc_matrix((data, (rows, cols)), shape=(len(tg), counts_train.shape[1]))\n",
    "    \n",
    "    print('done for', news_train.target_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cyclops/workspace/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:1228: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = -1.\n",
      "  \" = {}.\".format(self.n_jobs))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 1.0\n",
      "CPU times: user 18.2 s, sys: 1.15 s, total: 19.3 s\n",
      "Wall time: 10.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_20_lr_new = LogisticRegression(n_jobs=-1)\n",
    "_20_lr_new.fit(new_counts, news_train.target)\n",
    "yhat = _20_lr_new.predict(new_counts)\n",
    "print('Train acc:', sum(yhat == news_train.target)/len(news_train.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done alt.atheism\n",
      "done comp.graphics\n",
      "done comp.os.ms-windows.misc\n",
      "done comp.sys.ibm.pc.hardware\n",
      "done comp.sys.mac.hardware\n",
      "done comp.windows.x\n",
      "done misc.forsale\n",
      "done rec.autos\n",
      "done rec.motorcycles\n",
      "done rec.sport.baseball\n",
      "done rec.sport.hockey\n",
      "done sci.crypt\n",
      "done sci.electronics\n",
      "done sci.med\n",
      "done sci.space\n",
      "done soc.religion.christian\n",
      "done talk.politics.guns\n",
      "done talk.politics.mideast\n",
      "done talk.politics.misc\n",
      "done talk.religion.misc\n",
      "CPU times: user 55.7 s, sys: 1.79 s, total: 57.5 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_counts_test = lil_matrix(counts_test.shape, dtype='int16')\n",
    "for i in range(20):\n",
    "    tg = np.where(news_test.target == i)[0]\n",
    "    \n",
    "    rows = np.arange(0, len(tg), 1/200)\n",
    "    cols = np.tile(top_200[i], len(tg))\n",
    "    data = [1] * (len(rows))\n",
    "    \n",
    "    new_counts_test[tg] = csc_matrix((data, (rows, cols)), shape=(len(tg), counts_test.shape[1]))\n",
    "    \n",
    "    print('done', news_test.target_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "yhat = _20_lr_new.predict(new_counts_test)\n",
    "print('Test acc:', sum(yhat == news_test.target)/len(news_test.target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7532"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_test.target.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 o 0 p 0\n",
      "712 o 15 p 15\n",
      "748 o 5 p 5\n",
      "4451 o 14 p 14\n",
      "7227 o 15 p 15\n",
      "1456 o 8 p 8\n",
      "1214 o 4 p 4\n",
      "1305 o 10 p 10\n",
      "6465 o 7 p 7\n",
      "1401 o 9 p 9\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    idx = np.random.randint(news_test.target.shape[0])\n",
    "    yhat = _20_lr_new.predict(new_counts_test[idx])\n",
    "    y = news_test.target[idx]\n",
    "    print(idx, 'o', yhat[0], 'p', y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
